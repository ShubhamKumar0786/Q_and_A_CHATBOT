
# Q\&A Chatbot with Ollama 

This is a simple **Q\&A chatbot** built using **Streamlit**, **Ollama models**, and **LangChain**.
The chatbot allows you to select an **open-source LLM (Gemma or Mistral)**, adjust generation parameters (temperature, max tokens), and interact through a clean web interface.

---

## âš¡ Features

* Interactive **web app** powered by [Streamlit](https://streamlit.io/)
* Uses **Ollama models** (`Gemma3`, `Mistral`) for open-source LLM responses
* Adjustable **temperature** & **max tokens** for better control
* Simple **LangChain integration** for prompt templates and output parsing
* **LangSmith tracking** enabled for better observability

---

## ğŸ› ï¸ Installation & Setup

### 1. Clone the Repository

```bash
https://github.com/ShubhamKumar0786/Q_and_A_CHATBOT
```

### 2. Create Virtual Environment

```bash
python3.10 -m venv venv
```

Activate it:

* **Mac**

  ```bash
  source venv/bin/activate
  ```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Setup Environment Variables

Create a `.env` file in the project root and add your **LangChain API Key**:

```env
LANGCHAIN_API_KEY=your_langchain_api_key_here
LANGCHAIN_PROJECT=your_langchain_project_name_here
```

---

## â–¶ï¸ Run the App

```bash
streamlit run app.py
```

---

## ğŸ“‚ Project Structure

```
ğŸ“¦ ollama-chatbot
 â”£ ğŸ“œ app.py              # Streamlit frontend
 â”£ ğŸ“œ main.py             # Backend with LangChain + Ollama logic
 â”£ ğŸ“œ requirements.txt    # Dependencies
 â”£ ğŸ“œ .env                # Environment variables (ignored in GitHub)
 â”— ğŸ“œ README.md           # Project documentation
```

---

## ğŸ§© Requirements

* Python 3.10
* [Ollama](https://ollama.ai/) installed locally
* Streamlit
* LangChain Core & Community

Install manually if needed:

```bash
pip install streamlit ollama langchain_core langchain_community python-dotenv
```

---

## ğŸ“Š Example

After running the app, open the **browser interface**:

```
http://localhost:8501
```

Youâ€™ll see:

* A sidebar with **model selection & parameters**
* A chat input field to ask your questions
* Responses generated by Ollama models

---
# Preview
![Screenshot 2025-08-20 at 11 02 32 AM](https://github.com/user-attachments/assets/d1629eaa-9f37-4f73-9800-7c7670dc8a81)
![Screenshot 2025-08-20 at 11 03 12 AM](https://github.com/user-attachments/assets/38af8572-ab4f-4282-9411-32cfc8dd086c)
![Screenshot 2025-08-20 at 11 04 15 AM (1)](https://github.com/user-attachments/assets/46ebff7e-82ef-4bfc-99a8-9cc311ae86d8)





---

## ğŸ¤ Contributing

Pull requests are welcome!
- ğŸŒ [GitHub Profile](https://github.com/ShubhamKumar0786https://github.com/ShubhamKumar0786)  
- ğŸ“§ Email:shubhamkashyap9501@gmail.com
- LinkedIn: [Linkedin_link](https://www.linkedin.com/in/shubham0786/)

---



